{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377db0d9-9425-47d8-95e4-be7be227fc2b",
   "metadata": {},
   "source": [
    "# Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d390b3-0f40-47a5-8e4b-f8e3ad8c08d7",
   "metadata": {},
   "source": [
    "Artificial Neural Networks(ANN) are made up of several interconnected neurons which is organized in a layered fashion. Neurons in one layer pass messages to neurons in the next layer. Perceptrons are two layer neural network used for simple classification. Modern deep neural network consists of many hidden layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a444650-9bce-4dc8-9b35-122e64969d42",
   "metadata": {},
   "source": [
    "## Perceptrons "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda2044f-bf2f-4f55-9aee-768069e54237",
   "metadata": {},
   "source": [
    "perceptron is a simple neural network. Given an input vector x of m values (x1,x2, ..xm), outpus , we define the following function \n",
    "\n",
    "$f(x)  =  1$, if $wx+b > 0$  and $0$ otherwise\n",
    "$w$ is a vector of weights, and $wx$ is the dot product, $b$ is the bias. $wx+b$ defines a boundary hyperplane that changes position accordint to the values assigned to $w$ and $b$. \n",
    "\n",
    "Note: Hyperplane is a subspace whose dimension is one less than that of its ambient space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9868c946-4405-4b46-a075-81a6431a4d13",
   "metadata": {},
   "source": [
    "## Implementation of simple neural network \n",
    "Note : There are three ways of creating model in tf.keras \n",
    " * Sequenctial \n",
    " * Functional \n",
    " * Model subclassing \n",
    "Sequential() model is a linear pipeline of neural network layers. a layer is dense if each neuron is connected to all neurons located in the previous layer and to all neuron in the following layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bbc45c-f3bb-420b-9659-bf094b6d7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "from tensorflow import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5ca17-f502-4d48-9120-a5ad301197e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classes = 10   # prediction categories \n",
    "shape = 4  # input shape which has 4 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a345b41-3715-4736-b527-602bed0bfd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential() \n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        no_classes,\n",
    "        input_shape = (shape,), \n",
    "        kernel_initializer = 'zeros', \n",
    "        name = 'dense_layer',\n",
    "        activation = 'softmax')\n",
    ")                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360fdcf-3ba7-431d-8a41-0b3cdc4e2bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b8d459-78fd-482c-9e14-ff038e63e9ab",
   "metadata": {},
   "source": [
    "kernel_initializer parameter has few choices, the most common are \n",
    " * random_uniform: weights are initialized uniformly(-0.05,0.05)\n",
    " * random_normal - weight are initializedd according to gaussian distribution, with zero mean and a small sd of 0.05.\n",
    " * zero - weights are assigned to zero "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d4d75-6a6e-4935-a461-b7154b5ccac3",
   "metadata": {},
   "source": [
    "## -->  Multi-layer perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1809856f-b58a-4fd7-afb4-57f1a02b0623",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Activation functions : \n",
    "* sigmoid \n",
    "It is defined as $1/(1+exp(-x))$ and has the output changes in the range(0,1) when the input varies in the range (-inf, +inf). If z = wx+b is very large and positive then e^-z tends to 0. so sigmoid tends to 1. if z is very large and negative the e^-z tends to infinity and sigmoid tends to 0. \n",
    "\n",
    "* tanh \n",
    "which is defined as (e^z - e^-z) / ( e^z + e^-z) \n",
    "\n",
    "* relu: is defined as max(0,x) \n",
    "\n",
    "* elu \n",
    "* leaky relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ffb060-05c1-4c89-b1cc-4c003bf15aaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## One -hot encoding \n",
    "Categorical features can be encoded into binary vecotors of length same as the number of categories. \n",
    "The digit 3 in handwritten digit recognition is encoded into \n",
    "[0,0,0,1,0,0,0,0,0,0]. \n",
    "\n",
    "This type of representation is called one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0832de-ed50-4aeb-bd29-afdba3d1f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086427bf-5a42-403d-9f27-72ef51ba9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 128\n",
    "verbose = 1\n",
    "classes = 10\n",
    "h_hidden = 128\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7d6394-04da-4223-83a6-23288a94aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99757e87-3add-4e58-8630-3262966f4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train is 60000 rows of 28*28 shape\n",
    "shape = 784\n",
    "x_train = x_train.reshape(60000, shape) \n",
    "x_test = x_test.reshape(10000, shape) \n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f350ed-673a-4af8-9e8f-8ab0566d761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing \n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "print(x_train[0].shape) \n",
    "print(x_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5192d4a-c28e-4e4e-8ce0-4847aa967a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot representation of target categories \n",
    "y_train = tf.keras.utils.to_catgorical(y_train,classes) \n",
    "y_test = tf.keras.utils.to_categorical(y_test,classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232bb4a-2623-4673-a622-e9c57ff62cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential() \n",
    "model.add(keras.layers.Dense(\n",
    "    classes, \n",
    "    input_shape = (shape,),\n",
    "    name = 'dense_layer',\n",
    "    activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2fcaee-eef7-47cd-b44e-671f9178a68e",
   "metadata": {},
   "source": [
    "#### Binary cross entropy\n",
    "binary_crossentropy, which defines the binary logarithmic loss. Suppose that our model predicts p while the target is c, then the binary cross-entropy is defined as\n",
    "\n",
    "  $L(P, C) = −C l(p,c) − (1 − C) ln(1 − P)$. Note that this objective function is suitable for binary label prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732979e4-947c-48c9-bab9-0208f008222c",
   "metadata": {},
   "source": [
    "#### Categorical cross entropy \n",
    "categorical_crossentropy, which defines the multiclass logarithmic loss. Categorical cross-entropy compares the distribution of the predictions with the true distribution, with the probability of the true class set to 1 and 0 for the other classes. If the true class is c and the prediction is y, then the categorical cross-entropy is defined as:\n",
    "\n",
    "$L(c,p) = - {\\sum}C_i ln(p_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793fc58-bd8d-4851-9ceb-627d52338fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model compilation \n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7592d8-e10d-4c35-82fe-f7d9b36e11b4",
   "metadata": {},
   "source": [
    "### Epochs \n",
    "Epochs is the number of times the model is exposed to the training set.At each iteration the optimizre tries to adjust the weights sot that the objective function is minized. \n",
    "\n",
    "### Batch_size \n",
    "This is the number of training instances observed before the optimizer performs a weight update; there are usually many batches per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376ac6f-a12b-4c92-a5a1-30c2dc3e544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model training\n",
    "model.fit(x_train,y_train, batch_size = batch_size, \n",
    "          epochs = epochs , verbose = verbose, \n",
    "          validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28555570-70ab-4edc-a7eb-dca4dfb32734",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing the model\n",
    "test_loss, test_acc = model.evaluate(x_test,y_test) \n",
    "print('test_accuracy', test_acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f397539d-ecdb-451f-96f9-4e582aef4342",
   "metadata": {},
   "source": [
    "### Adding hidden layers \n",
    "    model = tf.keras.models.Sequential() \n",
    "    model.add(keras.layers.Dense(n_nodes, \n",
    "              input_shape = (shape, ) , \n",
    "              name = 'first layer', \n",
    "              activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(n_nodes,\n",
    "              name = 'second layer',\n",
    "              activation = 'relu')) \n",
    "    model.add(keras.layers.Dense(n_nodes,\n",
    "              name = 'third layer, \n",
    "              activation = 'softmax')) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecfe600-78bc-4b08-8931-932319a0ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 10\n",
    "shape = 23\n",
    "model = tf.keras.models.Sequential() \n",
    "model.add(keras.layers.Dense(n_nodes, \n",
    "          input_shape = (shape, ) , \n",
    "          name = 'first layer', \n",
    "          activation = 'relu'))\n",
    "model.add(keras.layers.Dense(n_nodes,\n",
    "          name = 'second layer',\n",
    "          activation = 'relu')) \n",
    "model.add(keras.layers.Dense(n_nodes,\n",
    "          name = 'third layer, \n",
    "          activation = 'softmax')) \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb433148-16d6-4390-9f44-72fa72451b53",
   "metadata": {},
   "source": [
    "## Adding dropout between \n",
    "    dropout_rato = 0.3\n",
    "    model.add(keras.layers.Dropout(dropout_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986d869-b31f-45e0-86e6-2c91f8482114",
   "metadata": {},
   "source": [
    "### Adding Regularization \n",
    "    from tf.keras.regularizars import l2, activity_l2\n",
    "    model.add(Dense(64, input_dim = 64, W_regularizer= l2(0.01), \n",
    "                    activity_regularizer = activity_l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302146b0-47f0-4b8e-b8fc-4fff332222db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
