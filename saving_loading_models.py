# -*- coding: utf-8 -*-
"""saving_loading_models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eyq-8XeMPe0_sb-0Ddex755W4LJbNDRX
"""

# !pip install h5py pyyaml

from __future__ import absolute_import, division, print_function 
import os 
import tensorflow as tf 
from tensorflow import keras

print(tf.__version__)

# loading the mnist dataset 
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

# taking the first 1000 images 
train_labels = train_labels[:1000] 
test_labels = test_labels[:1000] 

# reshaping the images 
train_images = train_images[:1000].reshape(-1, 28*28) / 255.0 
test_images = test_images[:1000].reshape(-1, 28*28) / 255.0

import matplotlib.pyplot as plt
from skimage import data, io , img_as_float

# plt.imshow(train_images[2], aspect = 'equal', cmap  = 'Blues')
# plt.grid(False)
# _ = plt.show()

# defining the model 

def create_model():
    model = tf.keras.models.Sequential([
        # input layer 
        keras.layers.Dense(
            units = 163, 
            activation = tf.nn.relu,
            input_shape = (784, )),
        # adding the drop out 
        keras.layers.Dropout(0.2), 
        # adding the output dense layer 
        keras.layers.Dense(units = 10 , activation = tf.nn.softmax) 
    ]) 

    # compiling the model 
    model.compile(
        optimizer = tf.keras.optimizers.Adam(), 
        loss = tf.keras.losses.sparse_categorical_crossentropy, 
        metrics = ['accuracy'] 
    )

    return model

# create the basic model instance 
model = create_model() 
model.summary()

"""#### Now tf.keras.callbacks.ModelCheckpoint is a callback that performs saving the checkpoints during and at the end of training. The callback takes a couple of arguments to configure checkpointing."""

checkpoint_path = 'training_1/cp.ckpt' 
checkpoint_dir = os.path.dirname(checkpoint_path) 

# create checkpoint callback 
cp_callback = tf.keras.callbacks.ModelCheckpoint(
    checkpoint_path, 
    save_weights_only = True, 
    verbose = 1 
)

model =  create_model() 
model.fit(
    train_images, 
    train_labels, 
    epochs = 10, 
    validation_data = (test_images, test_labels), 
    callbacks = [cp_callback] # passing callbacks to training 
)

!ls {checkpoint_dir}

model = create_model() 
loss, acc = model.evaluate(test_images, test_labels) 
print('Untrained model, accuracy : {:5.2f}%'.format(100*acc))

# load the weights from the checkpoint and re-evaluate 
model.load_weights(checkpoint_path) 
loss, acc = model.evaluate(test_images, test_labels) 
print('Restored model, accuracy : {:5.2f}%'.format(100*acc))

# adjusting the checkpoint frequency by training new model 
checkpoint_path = "training_2/cp-{epoch:04d}.ckpt" 
checkpoint_dir = os.path.dirname(checkpoint_path) 

cp_callback = tf.keras.callbacks.ModelCheckpoint(
    checkpoint_path, verbose = 1, save_weights_only = True, 

    # save werights by every 5 epoch 
    period = 5
) 

model = create_model() 
model.fit(train_images, train_labels, 
          epochs = 50 , 
          callbacks = [cp_callback], 
          validation_data = (test_images, test_labels), 
          verbose = 0)

!ls {checkpoint_dir}

latest = tf.train.latest_checkpoint(checkpoint_dir) 
latest

"""##### Note : The default tensorflow format only saves 5 most recent checkpoints """

# testing the latest chekpoint 
model = create_model() 
model.load_weights(latest) 
loss, acc = model.evaluate(test_images, test_labels) 
print('Restored model, accuracy : {:5.2f}%'.format(100*acc))

"""#### Notes : The checkpoint files contain only the trained weihgts in a binary format """

# another way of saving model 

# saving the weights 
model.save_weights('./checkpoints/my_checkpoint') 

# restore the weights 
model = create_model() 
model.load_weights('./checkpoints/my_checkpoint') 

loss, acc = model.evaluate(test_images, test_labels) 
print('Restored model, accuracy : {:5.2f}%'.format(100*acc))

"""# Save the entire model 
The entire model can be saved to a file that contains the weight values, the model's configuration, and even the optimizer's configuraton. This allows you to checkpoint a model and resume the training later- from the exact same state- without access to the original code.  
"""

model =  create_model() 
model.summary()

model.fit(train_images, train_labels, epochs = 5) 

# saving the model to hdf5 file 
model.save('my_model.h5')

# recreate the exactt same model, including the weights and optimizer. 
new_model = keras.models.load_model('my_model.h5') 
new_model.summary()

# now we can check its accuracy 
loss, acc = new_model.evaluate(test_images, test_labels) 
print('restored_model, accuracy : {:5.2f}%'.format(100*acc))

# A few random samples
use_samples = [2,3]
samples_to_predict = []

# Generate plots for samples
for sample in use_samples:
  # Generate a plot
  reshaped_image = test_images[sample].reshape((28, 28))
  plt.imshow(reshaped_image)
  plt.show()
  # Add sample to array for prediction
  samples_to_predict.append(test_images[sample])

# Convert into Numpy array
samples_to_predict = np.array(samples_to_predict)
samples_to_predict.shape

# Generate predictions for samples
predictions = model.predict(samples_to_predict)
print(predictions)

# Generate arg maxes for predictions
classes = np.argmax(predictions, axis = 1)
print(classes)

