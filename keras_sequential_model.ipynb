{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_sequential_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjEjjufieh15",
        "outputId": "2d41ab53-2c11-47b1-b1e0-97ed5258b5bc"
      },
      "source": [
        "import tensorflow as tf \n",
        "print('tensorflow version - ', tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version -  2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cYGn2zl58Y-"
      },
      "source": [
        "import numpy as np \n",
        "from random import randint \n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBNALXI66Jr9"
      },
      "source": [
        "train_labels = []\n",
        "train_samples = []"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7hW7g6U6Nsu"
      },
      "source": [
        "\n",
        "# generating the data \n",
        "\n",
        "for i in range(50):\n",
        "    # 5% of younger individuals who did experience side effects \n",
        "    random_younger = randint(13,64) \n",
        "    train_samples.append(random_younger)\n",
        "    train_labels.append(1)\n",
        "\n",
        "    # 5% of older individuals who did not experience side effects \n",
        "    random_older  = randint(65,100)\n",
        "    train_samples.append(random_older)\n",
        "    train_labels.append(0)\n",
        "\n",
        "\n",
        "for  i in range(1000):\n",
        "    # the 95% younger individuals who did not experience side effects \n",
        "    random_younger = randint(13,64)\n",
        "    train_samples.append(random_younger)\n",
        "    train_labels.append(0)\n",
        "\n",
        "\n",
        "    # the 95% of older individuals who did not experience side effects \n",
        "    random_older = randint(65,100)\n",
        "    train_samples.append(random_older)\n",
        "    train_labels.append(1)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnbG41ic8Xty"
      },
      "source": [
        "#  converting the train data into array \n",
        "train_labels = np.array(train_labels)\n",
        "train_samples = np.array(train_samples)\n",
        "\n",
        "train_labels,train_samples = shuffle(train_labels,train_samples)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZMwNh9I8nLz"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K6lbPXp-zBA"
      },
      "source": [
        "**Simple tf.keras Sequencial Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5g31l_j92DX"
      },
      "source": [
        "from tensorflow import keras \n",
        "from tensorflow.keras.models import Sequential  \n",
        "from tensorflow.keras.layers import Activation,Dense \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras.metrics import categorical_crossentropy"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRtH42zN_duL"
      },
      "source": [
        "model = Sequential([\n",
        "     Dense(units = 16, input_shape = (1,), activation = 'relu'),\n",
        "     Dense(units = 32, activation = 'relu'),\n",
        "     Dense(units = 2, activation = 'softmax')               \n",
        "])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omOaqK1CAWTZ",
        "outputId": "b8d8cb78-3086-496c-acae-5122c6cac1a7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VpeCxw5AYw1"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics  = ['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rSyeceKBUXm",
        "outputId": "cbcf150d-c35e-4610-ac0d-6831ce19558d"
      },
      "source": [
        "model.fit(x = scaled_train_samples,\n",
        "          y = train_labels,\n",
        "          validation_split = 0.1,\n",
        "          batch_size = 10, \n",
        "          epochs = 30, \n",
        "          shuffle = True,\n",
        "          verbose = 2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "189/189 - 1s - loss: 0.6418 - accuracy: 0.5513 - val_loss: 0.6358 - val_accuracy: 0.5810\n",
            "Epoch 2/30\n",
            "189/189 - 0s - loss: 0.6136 - accuracy: 0.6423 - val_loss: 0.6009 - val_accuracy: 0.7000\n",
            "Epoch 3/30\n",
            "189/189 - 0s - loss: 0.5810 - accuracy: 0.7333 - val_loss: 0.5694 - val_accuracy: 0.7333\n",
            "Epoch 4/30\n",
            "189/189 - 0s - loss: 0.5484 - accuracy: 0.7757 - val_loss: 0.5329 - val_accuracy: 0.7714\n",
            "Epoch 5/30\n",
            "189/189 - 0s - loss: 0.5110 - accuracy: 0.8206 - val_loss: 0.4950 - val_accuracy: 0.8190\n",
            "Epoch 6/30\n",
            "189/189 - 0s - loss: 0.4770 - accuracy: 0.8492 - val_loss: 0.4612 - val_accuracy: 0.8333\n",
            "Epoch 7/30\n",
            "189/189 - 0s - loss: 0.4453 - accuracy: 0.8582 - val_loss: 0.4287 - val_accuracy: 0.8857\n",
            "Epoch 8/30\n",
            "189/189 - 0s - loss: 0.4157 - accuracy: 0.8751 - val_loss: 0.3988 - val_accuracy: 0.8952\n",
            "Epoch 9/30\n",
            "189/189 - 0s - loss: 0.3892 - accuracy: 0.8868 - val_loss: 0.3720 - val_accuracy: 0.8952\n",
            "Epoch 10/30\n",
            "189/189 - 0s - loss: 0.3661 - accuracy: 0.8984 - val_loss: 0.3492 - val_accuracy: 0.9048\n",
            "Epoch 11/30\n",
            "189/189 - 0s - loss: 0.3469 - accuracy: 0.9101 - val_loss: 0.3300 - val_accuracy: 0.9048\n",
            "Epoch 12/30\n",
            "189/189 - 0s - loss: 0.3309 - accuracy: 0.9159 - val_loss: 0.3142 - val_accuracy: 0.9048\n",
            "Epoch 13/30\n",
            "189/189 - 0s - loss: 0.3178 - accuracy: 0.9164 - val_loss: 0.3009 - val_accuracy: 0.9238\n",
            "Epoch 14/30\n",
            "189/189 - 0s - loss: 0.3072 - accuracy: 0.9249 - val_loss: 0.2898 - val_accuracy: 0.9238\n",
            "Epoch 15/30\n",
            "189/189 - 0s - loss: 0.2983 - accuracy: 0.9243 - val_loss: 0.2807 - val_accuracy: 0.9429\n",
            "Epoch 16/30\n",
            "189/189 - 0s - loss: 0.2913 - accuracy: 0.9302 - val_loss: 0.2729 - val_accuracy: 0.9429\n",
            "Epoch 17/30\n",
            "189/189 - 0s - loss: 0.2854 - accuracy: 0.9280 - val_loss: 0.2667 - val_accuracy: 0.9429\n",
            "Epoch 18/30\n",
            "189/189 - 0s - loss: 0.2803 - accuracy: 0.9354 - val_loss: 0.2615 - val_accuracy: 0.9429\n",
            "Epoch 19/30\n",
            "189/189 - 0s - loss: 0.2765 - accuracy: 0.9307 - val_loss: 0.2565 - val_accuracy: 0.9429\n",
            "Epoch 20/30\n",
            "189/189 - 0s - loss: 0.2730 - accuracy: 0.9354 - val_loss: 0.2526 - val_accuracy: 0.9429\n",
            "Epoch 21/30\n",
            "189/189 - 0s - loss: 0.2700 - accuracy: 0.9317 - val_loss: 0.2494 - val_accuracy: 0.9476\n",
            "Epoch 22/30\n",
            "189/189 - 0s - loss: 0.2675 - accuracy: 0.9354 - val_loss: 0.2462 - val_accuracy: 0.9476\n",
            "Epoch 23/30\n",
            "189/189 - 0s - loss: 0.2655 - accuracy: 0.9365 - val_loss: 0.2436 - val_accuracy: 0.9476\n",
            "Epoch 24/30\n",
            "189/189 - 0s - loss: 0.2634 - accuracy: 0.9381 - val_loss: 0.2414 - val_accuracy: 0.9476\n",
            "Epoch 25/30\n",
            "189/189 - 0s - loss: 0.2620 - accuracy: 0.9370 - val_loss: 0.2394 - val_accuracy: 0.9476\n",
            "Epoch 26/30\n",
            "189/189 - 0s - loss: 0.2605 - accuracy: 0.9360 - val_loss: 0.2387 - val_accuracy: 0.9524\n",
            "Epoch 27/30\n",
            "189/189 - 0s - loss: 0.2593 - accuracy: 0.9413 - val_loss: 0.2361 - val_accuracy: 0.9476\n",
            "Epoch 28/30\n",
            "189/189 - 0s - loss: 0.2584 - accuracy: 0.9381 - val_loss: 0.2347 - val_accuracy: 0.9476\n",
            "Epoch 29/30\n",
            "189/189 - 0s - loss: 0.2572 - accuracy: 0.9386 - val_loss: 0.2337 - val_accuracy: 0.9524\n",
            "Epoch 30/30\n",
            "189/189 - 0s - loss: 0.2564 - accuracy: 0.9402 - val_loss: 0.2326 - val_accuracy: 0.9524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0443963290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rKWkyiAFN0k"
      },
      "source": [
        "# generating the data \n",
        "test_labels = []\n",
        "test_samples = []\n",
        "for i in range(10):\n",
        "    # 5% of younger individuals who did experience side effects \n",
        "    random_younger = randint(13,64) \n",
        "    test_samples.append(random_younger)\n",
        "    test_labels.append(1)\n",
        "\n",
        "    # 5% of older individuals who did not experience side effects \n",
        "    random_older  = randint(65,100)\n",
        "    test_samples.append(random_older)\n",
        "    test_labels.append(0)\n",
        "\n",
        "\n",
        "for  i in range(200):\n",
        "    # the 95% younger individuals who did not experience side effects \n",
        "    random_younger = randint(13,64)\n",
        "    test_samples.append(random_younger)\n",
        "    test_labels.append(0)\n",
        "\n",
        "\n",
        "    # the 95% of older individuals who did not experience side effects \n",
        "    random_older = randint(65,100)\n",
        "    test_samples.append(random_older)\n",
        "    test_labels.append(1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C61tB4C4OCOj"
      },
      "source": [
        "test_labels = np.array(test_labels)\n",
        "test_samples = np.array(test_samples)\n",
        "test_labels, test_samples = shuffle(test_labels, test_samples)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIJVN0upPBS-"
      },
      "source": [
        "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDf8q-D2PLYg"
      },
      "source": [
        "# prediction \n",
        "predictions = model.predict(x = scaled_test_samples, batch_size = 10, verbose = 0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqd92fSnPT5Z",
        "outputId": "a48e3635-e9af-4253-b08a-c23af3d98730"
      },
      "source": [
        "predictions"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03049275, 0.9695072 ],\n",
              "       [0.02855349, 0.9714466 ],\n",
              "       [0.85177594, 0.14822412],\n",
              "       [0.9763575 , 0.02364246],\n",
              "       [0.03255933, 0.9674406 ],\n",
              "       [0.8324732 , 0.16752672],\n",
              "       [0.2957711 , 0.7042289 ],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.81121415, 0.18878591],\n",
              "       [0.03049275, 0.9695072 ],\n",
              "       [0.9223918 , 0.07760822],\n",
              "       [0.9763837 , 0.02361634],\n",
              "       [0.9763706 , 0.0236294 ],\n",
              "       [0.07049647, 0.92950356],\n",
              "       [0.97626585, 0.02373413],\n",
              "       [0.81121415, 0.18878591],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.8848597 , 0.11514035],\n",
              "       [0.86920387, 0.13079616],\n",
              "       [0.9763051 , 0.02369481],\n",
              "       [0.2957711 , 0.7042289 ],\n",
              "       [0.03476093, 0.96523905],\n",
              "       [0.9763706 , 0.0236294 ],\n",
              "       [0.07506426, 0.9249357 ],\n",
              "       [0.93217796, 0.06782205],\n",
              "       [0.03255933, 0.9674406 ],\n",
              "       [0.7879443 , 0.21205564],\n",
              "       [0.14936936, 0.85063064],\n",
              "       [0.85177594, 0.14822412],\n",
              "       [0.08502412, 0.9149759 ],\n",
              "       [0.1687916 , 0.83120835],\n",
              "       [0.97639674, 0.02360328],\n",
              "       [0.8324732 , 0.16752672],\n",
              "       [0.1687916 , 0.83120835],\n",
              "       [0.03960213, 0.9603979 ],\n",
              "       [0.2957711 , 0.7042289 ],\n",
              "       [0.7879443 , 0.21205564],\n",
              "       [0.26642108, 0.73357886],\n",
              "       [0.03960213, 0.9603979 ],\n",
              "       [0.21357043, 0.7864295 ],\n",
              "       [0.9760793 , 0.02392075],\n",
              "       [0.05829293, 0.9417071 ],\n",
              "       [0.97634447, 0.02365554],\n",
              "       [0.07990261, 0.9200974 ],\n",
              "       [0.8848597 , 0.11514035],\n",
              "       [0.08502412, 0.9149759 ],\n",
              "       [0.06618672, 0.9338133 ],\n",
              "       [0.2957711 , 0.7042289 ],\n",
              "       [0.57326883, 0.42673117],\n",
              "       [0.86920387, 0.13079616],\n",
              "       [0.07506426, 0.9249357 ],\n",
              "       [0.93217796, 0.06782205],\n",
              "       [0.10196538, 0.89803463],\n",
              "       [0.07990261, 0.9200974 ],\n",
              "       [0.97626585, 0.02373413],\n",
              "       [0.02673415, 0.9732659 ],\n",
              "       [0.97633135, 0.02366862],\n",
              "       [0.9690391 , 0.03096093],\n",
              "       [0.6083878 , 0.3916122 ],\n",
              "       [0.81121415, 0.18878591],\n",
              "       [0.9763706 , 0.0236294 ],\n",
              "       [0.6083878 , 0.3916122 ],\n",
              "       [0.4289447 , 0.57105535],\n",
              "       [0.9753318 , 0.02466819],\n",
              "       [0.23899508, 0.761005  ],\n",
              "       [0.03255933, 0.9674406 ],\n",
              "       [0.10196538, 0.89803463],\n",
              "       [0.9762265 , 0.02377352],\n",
              "       [0.08502412, 0.9149759 ],\n",
              "       [0.93217796, 0.06782205],\n",
              "       [0.9670514 , 0.03294861],\n",
              "       [0.04809263, 0.9519074 ],\n",
              "       [0.03476093, 0.96523905],\n",
              "       [0.91132784, 0.08867214],\n",
              "       [0.32691368, 0.67308635],\n",
              "       [0.02342763, 0.97657233],\n",
              "       [0.6083878 , 0.3916122 ],\n",
              "       [0.7061087 , 0.29389125],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.97620016, 0.02379982],\n",
              "       [0.05829293, 0.9417071 ],\n",
              "       [0.07506426, 0.9249357 ],\n",
              "       [0.97630525, 0.02369481],\n",
              "       [0.9745616 , 0.02543837],\n",
              "       [0.03710569, 0.9628943 ],\n",
              "       [0.05128887, 0.9487111 ],\n",
              "       [0.6083878 , 0.3916122 ],\n",
              "       [0.97633135, 0.02366862],\n",
              "       [0.5373952 , 0.46260476],\n",
              "       [0.4289447 , 0.57105535],\n",
              "       [0.93217796, 0.06782205],\n",
              "       [0.9763706 , 0.0236294 ],\n",
              "       [0.97626585, 0.02373413],\n",
              "       [0.14936936, 0.85063064],\n",
              "       [0.23899508, 0.761005  ],\n",
              "       [0.97625273, 0.02374725],\n",
              "       [0.10196538, 0.89803463],\n",
              "       [0.9737552 , 0.02624484],\n",
              "       [0.03255933, 0.9674406 ],\n",
              "       [0.23899508, 0.761005  ],\n",
              "       [0.06618672, 0.9338133 ],\n",
              "       [0.23899508, 0.761005  ],\n",
              "       [0.14936936, 0.85063064],\n",
              "       [0.14936936, 0.85063064],\n",
              "       [0.1687916 , 0.83120835],\n",
              "       [0.10196538, 0.89803463],\n",
              "       [0.9760793 , 0.02392075],\n",
              "       [0.7353424 , 0.26465756],\n",
              "       [0.10196538, 0.89803463],\n",
              "       [0.9223918 , 0.07760822],\n",
              "       [0.2957711 , 0.7042289 ],\n",
              "       [0.9763183 , 0.02368171],\n",
              "       [0.9753318 , 0.02466819],\n",
              "       [0.04508607, 0.95491385],\n",
              "       [0.97259766, 0.02740239],\n",
              "       [0.9745616 , 0.02543837],\n",
              "       [0.9690391 , 0.03096093],\n",
              "       [0.8324732 , 0.16752672],\n",
              "       [0.7353424 , 0.26465756],\n",
              "       [0.91132784, 0.08867214],\n",
              "       [0.8848597 , 0.11514035],\n",
              "       [0.5011303 , 0.49886972],\n",
              "       [0.9618679 , 0.03813206],\n",
              "       [0.97089416, 0.02910587],\n",
              "       [0.9670514 , 0.03294861],\n",
              "       [0.97633135, 0.02366862],\n",
              "       [0.9690391 , 0.03096093],\n",
              "       [0.97634447, 0.02365554],\n",
              "       [0.94007635, 0.05992365],\n",
              "       [0.5011303 , 0.49886972],\n",
              "       [0.91132784, 0.08867214],\n",
              "       [0.21357043, 0.7864295 ],\n",
              "       [0.67507297, 0.32492703],\n",
              "       [0.05468534, 0.94531465],\n",
              "       [0.9618679 , 0.03813206],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.03710569, 0.9628943 ],\n",
              "       [0.04508607, 0.95491385],\n",
              "       [0.32691368, 0.67308635],\n",
              "       [0.89885956, 0.10114037],\n",
              "       [0.03049275, 0.9695072 ],\n",
              "       [0.21357043, 0.7864295 ],\n",
              "       [0.03710569, 0.9628943 ],\n",
              "       [0.11606482, 0.88393515],\n",
              "       [0.07049647, 0.92950356],\n",
              "       [0.9763837 , 0.02361634],\n",
              "       [0.9763575 , 0.02364246],\n",
              "       [0.89885956, 0.10114037],\n",
              "       [0.26642108, 0.73357886],\n",
              "       [0.9223918 , 0.07760822],\n",
              "       [0.02342763, 0.97657233],\n",
              "       [0.04225916, 0.95774084],\n",
              "       [0.05128887, 0.9487111 ],\n",
              "       [0.9753318 , 0.02466819],\n",
              "       [0.97089416, 0.02910587],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.9763183 , 0.02368171],\n",
              "       [0.64241934, 0.3575807 ],\n",
              "       [0.05468534, 0.94531465],\n",
              "       [0.97089416, 0.02910587],\n",
              "       [0.02342763, 0.97657233],\n",
              "       [0.9461446 , 0.05385535],\n",
              "       [0.9646449 , 0.0353551 ],\n",
              "       [0.06212284, 0.9378772 ],\n",
              "       [0.03255933, 0.9674406 ],\n",
              "       [0.06618672, 0.9338133 ],\n",
              "       [0.07506426, 0.9249357 ],\n",
              "       [0.94007635, 0.05992365],\n",
              "       [0.04225916, 0.95774084],\n",
              "       [0.9760793 , 0.02392075],\n",
              "       [0.03476093, 0.96523905],\n",
              "       [0.97639674, 0.02360328],\n",
              "       [0.976279  , 0.02372101],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.19017455, 0.8098255 ],\n",
              "       [0.9513672 , 0.04863283],\n",
              "       [0.21357043, 0.7864295 ],\n",
              "       [0.39376858, 0.60623145],\n",
              "       [0.57326883, 0.42673117],\n",
              "       [0.19017455, 0.8098255 ],\n",
              "       [0.97634447, 0.02365554],\n",
              "       [0.9763837 , 0.02361634],\n",
              "       [0.11606482, 0.88393515],\n",
              "       [0.976187  , 0.02381297],\n",
              "       [0.97625273, 0.02374725],\n",
              "       [0.2957711 , 0.7042289 ],\n",
              "       [0.39376858, 0.60623145],\n",
              "       [0.05829293, 0.9417071 ],\n",
              "       [0.9753318 , 0.02466819],\n",
              "       [0.8324732 , 0.16752672],\n",
              "       [0.4648533 , 0.53514665],\n",
              "       [0.93217796, 0.06782205],\n",
              "       [0.81121415, 0.18878591],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.06212284, 0.9378772 ],\n",
              "       [0.8848597 , 0.11514035],\n",
              "       [0.06212284, 0.9378772 ],\n",
              "       [0.86920387, 0.13079616],\n",
              "       [0.07049647, 0.92950356],\n",
              "       [0.03960213, 0.9603979 ],\n",
              "       [0.07049647, 0.92950356],\n",
              "       [0.19017455, 0.8098255 ],\n",
              "       [0.04225916, 0.95774084],\n",
              "       [0.23899508, 0.761005  ],\n",
              "       [0.86920387, 0.13079616],\n",
              "       [0.19017455, 0.8098255 ],\n",
              "       [0.26642108, 0.73357886],\n",
              "       [0.1687916 , 0.83120835],\n",
              "       [0.19017455, 0.8098255 ],\n",
              "       [0.07506426, 0.92493576],\n",
              "       [0.13182756, 0.8681724 ],\n",
              "       [0.35966057, 0.64033943],\n",
              "       [0.03960213, 0.9603979 ],\n",
              "       [0.06212284, 0.9378772 ],\n",
              "       [0.08502412, 0.9149759 ],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.89885956, 0.10114037],\n",
              "       [0.08502412, 0.9149759 ],\n",
              "       [0.9646449 , 0.0353551 ],\n",
              "       [0.91132784, 0.08867214],\n",
              "       [0.13182756, 0.8681724 ],\n",
              "       [0.13182756, 0.8681724 ],\n",
              "       [0.1687916 , 0.83120835],\n",
              "       [0.97620016, 0.02379982],\n",
              "       [0.7879443 , 0.21205564],\n",
              "       [0.9690391 , 0.03096093],\n",
              "       [0.64241934, 0.3575807 ],\n",
              "       [0.05468534, 0.94531465],\n",
              "       [0.95535   , 0.04465003],\n",
              "       [0.19017455, 0.8098255 ],\n",
              "       [0.76264566, 0.2373544 ],\n",
              "       [0.03710569, 0.9628943 ],\n",
              "       [0.09133476, 0.9086652 ],\n",
              "       [0.976279  , 0.02372101],\n",
              "       [0.976187  , 0.02381297],\n",
              "       [0.91132784, 0.08867214],\n",
              "       [0.23899508, 0.761005  ],\n",
              "       [0.97259766, 0.02740239],\n",
              "       [0.9461446 , 0.05385535],\n",
              "       [0.9587994 , 0.04120056],\n",
              "       [0.97620016, 0.02379982],\n",
              "       [0.7879443 , 0.21205564],\n",
              "       [0.9763706 , 0.0236294 ],\n",
              "       [0.9646449 , 0.0353551 ],\n",
              "       [0.9618679 , 0.03813206],\n",
              "       [0.32691368, 0.67308635],\n",
              "       [0.97620016, 0.02379982],\n",
              "       [0.04809263, 0.9519074 ],\n",
              "       [0.9737552 , 0.02624484],\n",
              "       [0.9762265 , 0.02377352],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.9587994 , 0.04120056],\n",
              "       [0.97639674, 0.02360328],\n",
              "       [0.21357043, 0.7864295 ],\n",
              "       [0.9745616 , 0.02543837],\n",
              "       [0.97259766, 0.02740239],\n",
              "       [0.09133476, 0.9086652 ],\n",
              "       [0.03049275, 0.9695072 ],\n",
              "       [0.8324732 , 0.16752672],\n",
              "       [0.1687916 , 0.83120835],\n",
              "       [0.97620016, 0.02379982],\n",
              "       [0.9690391 , 0.03096093],\n",
              "       [0.09133476, 0.9086652 ],\n",
              "       [0.9763706 , 0.0236294 ],\n",
              "       [0.9763706 , 0.0236294 ],\n",
              "       [0.97626585, 0.02373413],\n",
              "       [0.10196538, 0.89803463],\n",
              "       [0.13182756, 0.8681724 ],\n",
              "       [0.89885956, 0.10114037],\n",
              "       [0.9745616 , 0.02543837],\n",
              "       [0.02673415, 0.9732659 ],\n",
              "       [0.9737552 , 0.02624484],\n",
              "       [0.97625273, 0.02374725],\n",
              "       [0.04809263, 0.9519074 ],\n",
              "       [0.89885956, 0.10114037],\n",
              "       [0.5373952 , 0.46260476],\n",
              "       [0.05829293, 0.9417071 ],\n",
              "       [0.4289447 , 0.57105535],\n",
              "       [0.39376858, 0.6062314 ],\n",
              "       [0.32691368, 0.67308635],\n",
              "       [0.07506426, 0.9249357 ],\n",
              "       [0.06212284, 0.9378772 ],\n",
              "       [0.1687916 , 0.83120835],\n",
              "       [0.64241934, 0.3575807 ],\n",
              "       [0.4648533 , 0.53514665],\n",
              "       [0.26642108, 0.73357886],\n",
              "       [0.9763183 , 0.02368171],\n",
              "       [0.32691368, 0.67308635],\n",
              "       [0.9646449 , 0.0353551 ],\n",
              "       [0.04809262, 0.9519074 ],\n",
              "       [0.97633135, 0.02366862],\n",
              "       [0.04508607, 0.95491385],\n",
              "       [0.7879443 , 0.21205564],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.04508607, 0.95491385],\n",
              "       [0.19017455, 0.8098255 ],\n",
              "       [0.04225916, 0.95774084],\n",
              "       [0.76264566, 0.2373544 ],\n",
              "       [0.08502412, 0.9149759 ],\n",
              "       [0.04508607, 0.95491385],\n",
              "       [0.32691368, 0.67308635],\n",
              "       [0.97639674, 0.02360328],\n",
              "       [0.10196538, 0.89803463],\n",
              "       [0.9223918 , 0.07760822],\n",
              "       [0.05468534, 0.94531465],\n",
              "       [0.02673415, 0.9732659 ],\n",
              "       [0.9223918 , 0.07760822],\n",
              "       [0.19017455, 0.8098255 ],\n",
              "       [0.7879443 , 0.21205564],\n",
              "       [0.14936936, 0.85063064],\n",
              "       [0.7061087 , 0.29389125],\n",
              "       [0.10196538, 0.89803463],\n",
              "       [0.67507297, 0.32492703],\n",
              "       [0.9745616 , 0.02543837],\n",
              "       [0.03960213, 0.9603979 ],\n",
              "       [0.4289447 , 0.57105535],\n",
              "       [0.35966057, 0.64033943],\n",
              "       [0.81121415, 0.18878591],\n",
              "       [0.9587994 , 0.04120056],\n",
              "       [0.81121415, 0.18878591],\n",
              "       [0.94007635, 0.05992365],\n",
              "       [0.97623956, 0.02376039],\n",
              "       [0.13182756, 0.8681724 ],\n",
              "       [0.85177594, 0.14822412],\n",
              "       [0.67507297, 0.32492703],\n",
              "       [0.19017455, 0.8098255 ],\n",
              "       [0.05468534, 0.94531465],\n",
              "       [0.04508607, 0.95491385],\n",
              "       [0.976187  , 0.02381297],\n",
              "       [0.03255933, 0.9674406 ],\n",
              "       [0.64241934, 0.3575807 ],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.93217796, 0.06782205],\n",
              "       [0.35966057, 0.64033943],\n",
              "       [0.04809263, 0.9519074 ],\n",
              "       [0.97623956, 0.02376039],\n",
              "       [0.976187  , 0.02381297],\n",
              "       [0.97639674, 0.02360328],\n",
              "       [0.93217796, 0.06782205],\n",
              "       [0.32691368, 0.67308635],\n",
              "       [0.03710569, 0.9628943 ],\n",
              "       [0.94007635, 0.05992365],\n",
              "       [0.97626585, 0.02373413],\n",
              "       [0.19017455, 0.8098255 ],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.26642108, 0.73357886],\n",
              "       [0.81121415, 0.18878591],\n",
              "       [0.9618679 , 0.03813206],\n",
              "       [0.07049647, 0.92950356],\n",
              "       [0.07990261, 0.9200974 ],\n",
              "       [0.35966057, 0.64033943],\n",
              "       [0.03049275, 0.9695072 ],\n",
              "       [0.32691368, 0.67308635],\n",
              "       [0.1687916 , 0.83120835],\n",
              "       [0.8324732 , 0.16752672],\n",
              "       [0.14936936, 0.85063064],\n",
              "       [0.76264566, 0.2373544 ],\n",
              "       [0.04508607, 0.95491385],\n",
              "       [0.8324732 , 0.16752672],\n",
              "       [0.06212284, 0.9378772 ],\n",
              "       [0.5373952 , 0.46260476],\n",
              "       [0.02502774, 0.9749723 ],\n",
              "       [0.9763183 , 0.02368171],\n",
              "       [0.02342763, 0.97657233],\n",
              "       [0.4648533 , 0.53514665],\n",
              "       [0.1687916 , 0.83120835],\n",
              "       [0.97630525, 0.02369481],\n",
              "       [0.2957711 , 0.7042289 ],\n",
              "       [0.07049647, 0.92950356],\n",
              "       [0.9763183 , 0.02368171],\n",
              "       [0.02342763, 0.97657233],\n",
              "       [0.8848597 , 0.11514035],\n",
              "       [0.86920387, 0.13079616],\n",
              "       [0.04225916, 0.95774084],\n",
              "       [0.05468534, 0.94531465],\n",
              "       [0.35966057, 0.64033943],\n",
              "       [0.97625273, 0.02374725],\n",
              "       [0.97089416, 0.02910587],\n",
              "       [0.10196538, 0.89803463],\n",
              "       [0.81121415, 0.18878591],\n",
              "       [0.32691368, 0.67308635],\n",
              "       [0.9745616 , 0.02543837],\n",
              "       [0.03960213, 0.9603979 ],\n",
              "       [0.97623956, 0.02376039],\n",
              "       [0.67507297, 0.32492703],\n",
              "       [0.06618672, 0.9338133 ],\n",
              "       [0.976279  , 0.02372101],\n",
              "       [0.976187  , 0.02381297],\n",
              "       [0.2957711 , 0.7042289 ],\n",
              "       [0.07049647, 0.92950356],\n",
              "       [0.5011303 , 0.49886972],\n",
              "       [0.4648533 , 0.53514665],\n",
              "       [0.97623956, 0.02376039],\n",
              "       [0.64241934, 0.3575807 ],\n",
              "       [0.9737552 , 0.02624484],\n",
              "       [0.19017455, 0.8098255 ],\n",
              "       [0.97625273, 0.02374725],\n",
              "       [0.97621334, 0.02378667],\n",
              "       [0.09133476, 0.9086652 ],\n",
              "       [0.02855349, 0.9714466 ],\n",
              "       [0.09133476, 0.9086652 ],\n",
              "       [0.97089416, 0.02910587],\n",
              "       [0.97625273, 0.02374725],\n",
              "       [0.9753318 , 0.02466819],\n",
              "       [0.9763183 , 0.02368171],\n",
              "       [0.9763837 , 0.02361634],\n",
              "       [0.06212284, 0.9378772 ],\n",
              "       [0.9587994 , 0.04120056],\n",
              "       [0.03710569, 0.9628943 ],\n",
              "       [0.06212284, 0.9378772 ],\n",
              "       [0.10196538, 0.89803463],\n",
              "       [0.4648533 , 0.53514665],\n",
              "       [0.03960213, 0.9603979 ],\n",
              "       [0.02855349, 0.9714466 ],\n",
              "       [0.02855349, 0.9714466 ],\n",
              "       [0.9760793 , 0.02392075],\n",
              "       [0.9513672 , 0.04863283],\n",
              "       [0.05128887, 0.9487111 ],\n",
              "       [0.976279  , 0.02372101],\n",
              "       [0.08502412, 0.9149759 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VlRqA4ePWxK"
      },
      "source": [
        "rounded_predictions = np.argmax(predictions, axis = -1 )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaLuRuFmP7aU",
        "outputId": "f2c226f7-701d-4ed3-d84c-e629e0dab94e"
      },
      "source": [
        "rounded_predictions"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNOsPd-HP9qQ"
      },
      "source": [
        "%matplotlib inline \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhat3VX6eM1M"
      },
      "source": [
        "cm = confusion_matrix(y_true=test_labels, y_pred = rounded_predictions)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpkLZcj-eVGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ddb5f1-f298-42a1-d4f1-498adec04e63"
      },
      "source": [
        "cm"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[195,  15],\n",
              "       [ 10, 200]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6NQPXOBfzTz"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}